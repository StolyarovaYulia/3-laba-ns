{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "cup1 =   [0,1,0,0,0,\n",
        "           1,0,1,1,0,\n",
        "           1,1,1,0,1,\n",
        "           1,0,1,1,0,\n",
        "           1,1,1,0,0]\n",
        "\n",
        "cup2 =   [0,1,0,0,0,\n",
        "           1,0,1,1,0,\n",
        "           1,1,1,0,1,\n",
        "           1,0,1,1,0,\n",
        "           1,1,1,0,0]\n",
        "\n",
        "cup3 =   [0,1,0,0,0,\n",
        "           1,0,1,1,0,\n",
        "           1,1,1,0,1,\n",
        "           1,0,1,1,0,\n",
        "           1,1,1,0,0]\n",
        "\n",
        "cup4 =   [0,1,0,0,0,\n",
        "           1,0,1,1,0,\n",
        "           1,1,1,0,1,\n",
        "           1,0,1,1,0,\n",
        "           1,1,1,0,0]\n",
        "\n",
        "cup5 =   [0,1,0,0,0,\n",
        "           1,0,1,1,0,\n",
        "           1,1,1,0,1,\n",
        "           1,0,1,1,0,\n",
        "           1,1,1,0,0]\n",
        "\n",
        "butle1 =  [0,1,1,0,0,\n",
        "            0,1,1,0,0,\n",
        "            1,0,0,1,0,\n",
        "            1,0,0,1,0,\n",
        "            1,1,1,1,0]\n",
        "\n",
        "butle2 =  [0,1,1,0,0,\n",
        "            0,1,1,0,0,\n",
        "            1,0,0,1,0,\n",
        "            1,0,0,1,0,\n",
        "            1,1,1,1,0]\n",
        "\n",
        "butle3 =  [0,1,1,0,0,\n",
        "            0,1,1,0,0,\n",
        "            1,0,0,1,0,\n",
        "            1,0,0,1,0,\n",
        "            1,1,1,1,0]\n",
        "\n",
        "butle4 =  [0,1,1,0,0,\n",
        "            0,1,1,0,0,\n",
        "            1,0,0,1,0,\n",
        "            1,0,0,1,0,\n",
        "            1,1,1,1,0]\n",
        "\n",
        "butle5 =  [0,1,1,0,0,\n",
        "            0,1,1,0,0,\n",
        "            1,0,0,1,0,\n",
        "            1,0,0,1,0,\n",
        "            1,1,1,1,0]\n",
        "\n",
        "def get_cup():\n",
        "    return np.array([cup1, cup2, cup3, cup4, cup5])\n",
        "\n",
        "def get_butle():\n",
        "    return np.array([butle1, butle2, butle3, butle4, butle5])\n",
        "\n",
        "def get_conv_numbers(number):\n",
        "    if number == 1:\n",
        "        return [[np.sum(row) for row in num] for num in get_butle().reshape(5, 5, 5)]\n",
        "    elif number == 0:\n",
        "        return [[np.sum(row) for row in num] for num in get_cup().reshape(5, 5, 5)]\n",
        "    else:\n",
        "        raise Exception(\"Нет такой цифры, введите либо чашку либо бутылку\")\n",
        "\n",
        "def get_conv_number(number):\n",
        "    return np.array([np.sum(row) for row in number.reshape(5, 5)])"
      ],
      "metadata": {
        "id": "yY4gOwbXw6f5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, accuracy_score\n",
        "\n",
        "def add_bias_feature(a):\n",
        "    a_extended = np.zeros((a.shape[0],a.shape[1]+1))\n",
        "    a_extended[:,:-1] = a\n",
        "    a_extended[:,-1] = int(1)  \n",
        "    return a_extended\n",
        "\n",
        "class SVM(object):\n",
        "    def __init__(self, etha=0.01, alpha=0.1, epochs=200):\n",
        "        self._epochs = epochs\n",
        "        self._etha = etha\n",
        "        self._alpha = alpha\n",
        "        self._w = None # Веса модели\n",
        "        self.history_w = [] # История изменения весов для показа\n",
        "        self.train_errors = None # Ошибки обучения модели\n",
        "        self.val_errors = None # Ошибки проверки качества модели\n",
        "        self.train_loss = None # Значение функции потерь модели при обучении\n",
        "        self.val_loss = None # Значение функции потерь модели при проверке\n",
        "\n",
        "    def fit(self, X_train, Y_train, X_val, Y_val, verbose=False): #arrays: X; Y =-1,1\n",
        "        '''\n",
        "        Метод обучения модели, значения массивов y принимают значения либо 1 либо -1\n",
        "        1 - если на выходе должна быть еденица, -1 если ноль \n",
        "        '''\n",
        "        if len(set(Y_train)) != 2 or len(set(Y_val)) != 2: # Проверка, что бы количество классов было равно 2 (бин классификация)\n",
        "            raise ValueError(\"Number of classes in Y is not equal 2!\")\n",
        "\n",
        "        X_train = add_bias_feature(X_train) # Добавление признака смещения в каждый столбец\n",
        "        X_val = add_bias_feature(X_val)\n",
        "        self._w = np.random.normal(loc=0, scale=0.05, size=X_train.shape[1]) # Инициализируем веса случайными значениями\n",
        "        self.history_w.append(self._w) # Записываем начальные веса в историю весов\n",
        "        # Инициализируем списки\n",
        "        train_errors = []\n",
        "        val_errors = []\n",
        "        train_loss_epoch = []\n",
        "        val_loss_epoch = []\n",
        "        # Начало тренировки модели\n",
        "        for epoch in range(self._epochs):\n",
        "            tr_err = 0\n",
        "            val_err = 0\n",
        "            tr_loss = 0\n",
        "            val_loss = 0\n",
        "            for i,x in enumerate(X_train): # Индексируем элементы обучающей выборки\n",
        "                margin = Y_train[i]*np.dot(self._w,X_train[i]) # Находим значение отступа модели\n",
        "                if margin >= 1: # классифицируем верно, если отступ элемента больше радиуса полосы модели\n",
        "                    self._w -= self._etha*self._alpha*self._w/self._epochs # Изменяем веса пропорционально эпохе обучения\n",
        "                    tr_loss += self.soft_margin_loss(X_train[i],Y_train[i]) # Увеличения значерия потерь\n",
        "                else: # классифицируем неверно или попадаем на полосу разделения при 0<m<1\n",
        "                    self._w += self._etha*(Y_train[i]*X_train[i] - self._alpha*self._w/self._epochs)\n",
        "                    tr_err += 1\n",
        "                    tr_loss += self.soft_margin_loss(X_train[i],Y_train[i])\n",
        "                self.history_w.append(self._w)\n",
        "            for i,x in enumerate(X_val): # Цикл проверки качества модели\n",
        "                val_loss += self.soft_margin_loss(X_val[i], Y_val[i])\n",
        "                val_err += (Y_val[i]*np.dot(self._w,X_val[i])<1).astype(int)\n",
        "            if verbose and epoch % 20 == 0:\n",
        "                print('epoch {}. Errors={}. Mean Hinge_loss={}'\\\n",
        "                      .format(epoch,val_err, val_loss))\n",
        "            train_errors.append(tr_err)\n",
        "            val_errors.append(val_err)\n",
        "            train_loss_epoch.append(tr_loss)\n",
        "            val_loss_epoch.append(val_loss)\n",
        "        self.history_w = np.array(self.history_w)    \n",
        "        self.train_errors = np.array(train_errors)\n",
        "        self.val_errors = np.array(val_errors)\n",
        "        self.train_loss = np.array(train_loss_epoch)\n",
        "        self.val_loss = np.array(val_loss_epoch)                    \n",
        "\n",
        "    def predict(self, X:np.array) -> np.array:\n",
        "        y_pred = []\n",
        "        X_extended = add_bias_feature(X)\n",
        "        for i in range(len(X_extended)):\n",
        "            y_pred.append(np.sign(np.dot(self._w,X_extended[i])))\n",
        "        return np.array(y_pred)         \n",
        "\n",
        "    def hinge_loss(self, x, y):\n",
        "        return max(0,1 - y*np.dot(x, self._w))\n",
        "\n",
        "    def soft_margin_loss(self, x, y):\n",
        "        return self.hinge_loss(x,y)+self._alpha*np.dot(self._w, self._w)\n",
        "\n",
        "\n",
        "svm = SVM(epochs=1000)\n",
        "svm.fit(np.vstack([get_conv_numbers(0), get_conv_numbers(1)]), np.array([-1,-1,-1,-1,-1,1,1,1,1,1]),\n",
        "        np.vstack([get_conv_numbers(0)[3:], get_conv_numbers(1)[3:]]), np.array([-1,-1,-1,1,1,1]),\n",
        "        verbose=True)\n",
        "# Предсказать число, если чашка то output = -1, иначе 1\n",
        "number =  np.array([0,1,0,0,0,\n",
        "                    1,0,1,1,0,\n",
        "                    1,1,1,0,1,\n",
        "                    1,0,1,1,0,\n",
        "                    1,1,1,0,0])\n",
        "\n",
        "y_pred = svm.predict(np.array([get_conv_number(number)]))\n",
        "\n",
        "print(\"Class: \" + str(svm.predict(np.array([get_conv_number(number)]))))\n",
        "print(\"Accuracy: \" + str(accuracy_score(cup3, number)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn-OB7dAw6in",
        "outputId": "909a63e6-55ce-4fe5-d04e-06a541043fdb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0. Errors=4. Mean Hinge_loss=4.631440050093464\n",
            "epoch 20. Errors=1. Mean Hinge_loss=2.2861010071903376\n",
            "epoch 40. Errors=1. Mean Hinge_loss=2.28579415202672\n",
            "epoch 60. Errors=1. Mean Hinge_loss=2.2854873780882894\n",
            "epoch 80. Errors=1. Mean Hinge_loss=2.285180685350861\n",
            "epoch 100. Errors=1. Mean Hinge_loss=2.284874073790253\n",
            "epoch 120. Errors=1. Mean Hinge_loss=2.2845675433822956\n",
            "epoch 140. Errors=1. Mean Hinge_loss=2.28426109410283\n",
            "epoch 160. Errors=1. Mean Hinge_loss=2.2839547259277015\n",
            "epoch 180. Errors=1. Mean Hinge_loss=2.283648438832763\n",
            "epoch 200. Errors=1. Mean Hinge_loss=2.2833422327938755\n",
            "epoch 220. Errors=1. Mean Hinge_loss=2.2830361077869132\n",
            "epoch 240. Errors=1. Mean Hinge_loss=2.2827300637877506\n",
            "epoch 260. Errors=1. Mean Hinge_loss=2.2824241007722734\n",
            "epoch 280. Errors=1. Mean Hinge_loss=2.2821182187163767\n",
            "epoch 300. Errors=1. Mean Hinge_loss=2.2818124175959644\n",
            "epoch 320. Errors=1. Mean Hinge_loss=2.281506697386944\n",
            "epoch 340. Errors=1. Mean Hinge_loss=2.281201058065233\n",
            "epoch 360. Errors=1. Mean Hinge_loss=2.2808954996067627\n",
            "epoch 380. Errors=1. Mean Hinge_loss=2.2805900219874626\n",
            "epoch 400. Errors=1. Mean Hinge_loss=2.280284625183276\n",
            "epoch 420. Errors=1. Mean Hinge_loss=2.2799793091701486\n",
            "epoch 440. Errors=1. Mean Hinge_loss=2.279674073924043\n",
            "epoch 460. Errors=1. Mean Hinge_loss=2.279368919420924\n",
            "epoch 480. Errors=1. Mean Hinge_loss=2.2790638456367645\n",
            "epoch 500. Errors=1. Mean Hinge_loss=2.278758852547545\n",
            "epoch 520. Errors=1. Mean Hinge_loss=2.2784539401292583\n",
            "epoch 540. Errors=1. Mean Hinge_loss=2.2781491083579026\n",
            "epoch 560. Errors=1. Mean Hinge_loss=2.2778443572094806\n",
            "epoch 580. Errors=1. Mean Hinge_loss=2.2775396866600066\n",
            "epoch 600. Errors=1. Mean Hinge_loss=2.277235096685503\n",
            "epoch 620. Errors=1. Mean Hinge_loss=2.276930587261999\n",
            "epoch 640. Errors=1. Mean Hinge_loss=2.27662615836553\n",
            "epoch 660. Errors=1. Mean Hinge_loss=2.276321809972142\n",
            "epoch 680. Errors=1. Mean Hinge_loss=2.2760175420578883\n",
            "epoch 700. Errors=1. Mean Hinge_loss=2.2757133545988326\n",
            "epoch 720. Errors=1. Mean Hinge_loss=2.2754092475710412\n",
            "epoch 740. Errors=1. Mean Hinge_loss=2.275105220950593\n",
            "epoch 760. Errors=1. Mean Hinge_loss=2.2748012747135715\n",
            "epoch 780. Errors=1. Mean Hinge_loss=2.274497408836069\n",
            "epoch 800. Errors=1. Mean Hinge_loss=2.274193623294187\n",
            "epoch 820. Errors=1. Mean Hinge_loss=2.273889918064033\n",
            "epoch 840. Errors=1. Mean Hinge_loss=2.273586293121726\n",
            "epoch 860. Errors=1. Mean Hinge_loss=2.2732827484433886\n",
            "epoch 880. Errors=1. Mean Hinge_loss=2.272979284005155\n",
            "epoch 900. Errors=1. Mean Hinge_loss=2.272675899783164\n",
            "epoch 920. Errors=1. Mean Hinge_loss=2.2723725957535645\n",
            "epoch 940. Errors=1. Mean Hinge_loss=2.2720693718925116\n",
            "epoch 960. Errors=1. Mean Hinge_loss=2.2717662281761704\n",
            "epoch 980. Errors=1. Mean Hinge_loss=2.2714631645807115\n",
            "Class: [-1.]\n",
            "Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Добро пожаловать в Colaboratory!",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}